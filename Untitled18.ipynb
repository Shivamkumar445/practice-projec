{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed4ad738",
   "metadata": {},
   "source": [
    "Restaurant Food Cost\n",
    "\n",
    "Project Description\n",
    "\n",
    "Who doesn’t love food? All of us must have craving for at least a few favourite food items, we may also have a few places where we like to get them, a restaurant which serves our favourite food the way we want it to be. But there is one factor that will make us reconsider having our favourite food from our favourite restaurant, the cost. Here in this hackathon, you will be predicting the cost of the food served by the restaurants across different cities in India. You will use your Data Science skills to investigate the factors that really affect the cost, and who knows maybe you will even gain some very interesting insights that might help you choose what to eat and from where.\n",
    "\n",
    "You are provided with following 2 files:\n",
    "1.     train.csv : Use this dataset to train the model. This file contains all the details related to restaurant food cost as well as the target variable “cost”. You have to train your model using this file.\n",
    "2.     test.csv : Use the trained model to predict the cost of a two person meal.\n",
    "\n",
    "Dataset Attributes\n",
    "TITLE: The feature of the restaurant which can help identify what and for whom it is suitable for.\n",
    "RESTAURANT_ID: A unique ID for each restaurant.\n",
    "CUISINES: The variety of cuisines that the restaurant offers.\n",
    "TIME: The open hours of the restaurant.\n",
    "CITY: The city in which the restaurant is located.\n",
    "LOCALITY: The locality of the restaurant.\n",
    "RATING: The average rating of the restaurant by customers.\n",
    "VOTES: The overall votes received by the restaurant.\n",
    "COST: The average cost of a two-person meal.\n",
    "\n",
    "Dataset Link-\n",
    "•\thttps://github.com/FlipRoboTechnologies/ML-Datasets/tree/main/Restaurant%20Food%20Cost\n",
    "\n",
    "•\thttps://github.com/FlipRoboTechnologies/ML-Datasets/blob/main/Restaurant%20Food%20Cost/Data_Test.xlsx\n",
    "•\thttps://github.com/FlipRoboTechnologies/ML-Datasets/blob/main/Restaurant%20Food%20Cost/Data_Train.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ed855",
   "metadata": {},
   "source": [
    "Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58918a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('Data_Train.xlsx')\n",
    "test = pd.read_excel('Data_Test.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec13a5e",
   "metadata": {},
   "source": [
    "Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f590b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate records... didn't remove the duplicate records as it was bringing score down\n",
    "train.duplicated().sum(), test.duplicated().sum()\n",
    "#train.drop_duplicates(keep='first', inplace=True)\n",
    "#train.reset_index(inplace=True)\n",
    "#test.drop_duplicates(keep='first', inplace=True)\n",
    "#test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ba1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()\n",
    "#train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    print(\"Unique values in\", i, train[i].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592b447",
   "metadata": {},
   "source": [
    "Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge train and test\n",
    "df = train.append(test,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975797ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['TITLE', 'CUISINES', 'TIME', 'CITY', 'LOCALITY', 'RATING', 'VOTES', 'COST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a68add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_closed(time):\n",
    "    a = re.findall('Closed \\(.*?\\)', time)\n",
    "    if a != []:\n",
    "        return a[0]\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "df['CLOSED'] = df['TIME'].apply(extract_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIME'] = df['TIME'].str.replace(r'Closed \\(.*?\\)','')\n",
    "#df['TIME'] = df['TIME'].str.replace(r'Closed...','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabea9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RATING'] = df['RATING'].str.replace('NEW', '1')\n",
    "df['RATING'] = df['RATING'].str.replace('-', '1').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a368217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VOTES'] = df['VOTES'].str.replace(' votes', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CITY'].fillna('Missing', inplace=True)  \n",
    "df['LOCALITY'].fillna('Missing', inplace=True)  \n",
    "df['RATING'].fillna(3.8, inplace=True)  \n",
    "df['VOTES'].fillna(0.0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COST'] = df['COST'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd681f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TITLE'].nunique(), df['CUISINES'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdac23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mean = df.groupby(['CITY'], axis=0).agg({'RATING': 'mean'}).reset_index()\n",
    "calc_mean.columns = ['CITY','CITY_MEAN_RATING']\n",
    "df = df.merge(calc_mean, on=['CITY'],how='left')\n",
    "\n",
    "calc_mean = df.groupby(['LOCALITY'], axis=0).agg({'RATING': 'mean'}).reset_index()\n",
    "calc_mean.columns = ['LOCALITY','LOCALITY_MEAN_RATING']\n",
    "df = df.merge(calc_mean, on=['LOCALITY'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630440a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf1 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_title = tf1.fit_transform(df['TITLE'])\n",
    "df_title = pd.DataFrame(data=df_title.toarray(), columns=tf1.get_feature_names())\n",
    "\n",
    "tf2 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_cuisines = tf2.fit_transform(df['CUISINES'])\n",
    "df_cuisines = pd.DataFrame(data=df_cuisines.toarray(), columns=tf2.get_feature_names())\n",
    "\n",
    "tf3 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_city = tf3.fit_transform(df['CITY'])\n",
    "df_city = pd.DataFrame(data=df_city.toarray(), columns=tf3.get_feature_names())\n",
    "\n",
    "tf4 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_locality = tf4.fit_transform(df['LOCALITY'])\n",
    "df_locality = pd.DataFrame(data=df_locality.toarray(), columns=tf4.get_feature_names())\n",
    "\n",
    "tf5 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_time = tf5.fit_transform(df['TIME'])\n",
    "df_time = pd.DataFrame(data=df_time.toarray(), columns=tf5.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3375a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_title, df_cuisines, df_city, df_locality, df_time], axis=1) \n",
    "df.drop(['TITLE', 'CUISINES', 'CITY', 'LOCALITY', 'TIME'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584906b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['CLOSED'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace45793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['COST'].isnull()!=True]\n",
    "test_df = df[df['COST'].isnull()==True]\n",
    "test_df.drop('COST', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['COST'] = np.log1p(train_df['COST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c1f43",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66096e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(labels=['COST'], axis=1)\n",
    "y = train_df['COST'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc073e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_cv.shape, y_cv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fc485",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt \n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cfbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_cv, label=y_cv)\n",
    "\n",
    "param = {'objective': 'regression',\n",
    "         'boosting': 'gbdt',  \n",
    "         'metric': 'l2_root',\n",
    "         'learning_rate': 0.05, \n",
    "         'num_iterations': 350,\n",
    "         'num_leaves': 31,\n",
    "         'max_depth': -1,\n",
    "         'min_data_in_leaf': 15,\n",
    "         'bagging_fraction': 0.85,\n",
    "         'bagging_freq': 1,\n",
    "         'feature_fraction': 0.55\n",
    "         }\n",
    "\n",
    "lgbm = lgb.train(params=param,\n",
    "                 verbose_eval=50,\n",
    "                 train_set=train_data,\n",
    "                 valid_sets=[test_data])\n",
    "\n",
    "y_pred_lgbm = lgbm.predict(X_cv)\n",
    "print('RMSLE:', sqrt(mean_squared_log_error(np.exp(y_cv), np.exp(y_pred_lgbm))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca74e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "br = BaggingRegressor(base_estimator=None, n_estimators=30, max_samples=0.9, max_features=1.0, bootstrap=True, \n",
    "                      bootstrap_features=True, oob_score=True, warm_start=False, n_jobs=1, random_state=42, verbose=1)\n",
    "br.fit(X_train, y_train)\n",
    "y_pred_br = br.predict(X_cv)\n",
    "print('RMSLE:', sqrt(mean_squared_log_error(np.exp(y_cv), np.exp(y_pred_br))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa03407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=40, criterion='mse', max_depth=None, min_samples_split=4, min_samples_leaf=1, \n",
    "                           min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                           random_state=42, verbose=1, warm_start=False)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_cv)\n",
    "print('RMSLE:', sqrt(mean_squared_log_error(np.exp(y_cv), np.exp(y_pred_rf))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4662ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_lgbm*0.70 + y_pred_br*0.15 +  y_pred_rf*0.15\n",
    "print('RMSLE:', sqrt(mean_squared_log_error(np.exp(y_cv), np.exp(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26719956",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce782b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain = train_df.drop(labels='COST', axis=1)\n",
    "#ytrain = train_df['COST'].values\n",
    "Xtest = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain.shape, ytrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02297fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "errlgb = []\n",
    "y_pred_totlgb = []\n",
    "\n",
    "fold = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in fold.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    param = {'objective': 'regression',\n",
    "             'boosting': 'gbdt',\n",
    "             'metric': 'l2_root',\n",
    "             'learning_rate': 0.05,\n",
    "             'num_iterations': 350,\n",
    "             'num_leaves': 31,\n",
    "             'max_depth': -1,\n",
    "             'min_data_in_leaf': 15,\n",
    "             'bagging_fraction': 0.85,\n",
    "             'bagging_freq': 1,\n",
    "             'feature_fraction': 0.55\n",
    "             }\n",
    "\n",
    "    lgbm = LGBMRegressor(**param)\n",
    "    lgbm.fit(X_train, y_train,\n",
    "             eval_set=[(X_test, y_test)],\n",
    "             verbose=0,\n",
    "             early_stopping_rounds=100\n",
    "             )\n",
    "\n",
    "    y_pred_lgbm = lgbm.predict(X_test)\n",
    "    print(\"RMSE LGBM: \", sqrt(mean_squared_log_error(np.exp(y_test), np.exp(y_pred_lgbm))))\n",
    "\n",
    "    errlgb.append(sqrt(mean_squared_log_error(np.exp(y_test), np.exp(y_pred_lgbm))))\n",
    "    p = lgbm.predict(Xtest)\n",
    "    y_pred_totlgb.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "err_br = []\n",
    "y_pred_totbr = []\n",
    "\n",
    "fold = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in fold.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    br = BaggingRegressor(base_estimator=None, n_estimators=30, max_samples=1.0, max_features=1.0, bootstrap=True,\n",
    "                          bootstrap_features=True, oob_score=False, warm_start=False, n_jobs=1, random_state=42, verbose=0)\n",
    "    \n",
    "    br.fit(X_train, y_train)\n",
    "    y_pred_br = br.predict(X_test)\n",
    "\n",
    "    print(\"RMSE BR:\", sqrt(mean_squared_log_error(np.exp(y_test), np.exp(y_pred_br))))\n",
    "\n",
    "    err_br.append(sqrt(mean_squared_log_error(np.exp(y_test), np.exp(y_pred_br))))\n",
    "    p = br.predict(Xtest)\n",
    "    y_pred_totbr.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b543ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "err_rf = []\n",
    "y_pred_totrf = []\n",
    "\n",
    "fold = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in fold.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=40, criterion='mse', max_depth=None, min_samples_split=4, min_samples_leaf=1, \n",
    "                           min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                           random_state=42, verbose=0, warm_start=False)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "    print(\"RMSE RF: \", sqrt(mean_squared_log_error(np.exp(y_test), np.exp(y_pred_rf))))\n",
    "\n",
    "    err_rf.append(sqrt(mean_squared_log_error(np.exp(y_test), np.exp(y_pred_rf))))\n",
    "    p = rf.predict(Xtest)\n",
    "    y_pred_totrf.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570aa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(errlgb,0), np.mean(err_br,0), np.mean(err_rf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_final = np.exp(np.mean(y_pred_totlgb,0))\n",
    "br_final = np.exp(np.mean(y_pred_totbr,0))\n",
    "rf_final = np.exp(np.mean(y_pred_totrf,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42628c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (lgbm_final*0.70 + br_final*0.215 + rf_final*.15) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ba256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(data=y_pred, columns=['COST'])\n",
    "writer = pd.ExcelWriter('Output.xlsx', engine='xlsxwriter')\n",
    "df_sub.to_excel(writer,sheet_name='Sheet1', index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
